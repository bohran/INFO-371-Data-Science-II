{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "INFO 371 Winter 2019\n",
    "\n",
    "Lab created by: Zening Qu\n",
    "\n",
    "Deadline: 11:59pm Feb 26, 2019\n",
    "\n",
    "In this lab we will build multinomial naive bayes classifiers to predict movie ratings (`fresh` or `rotten`) based on user quotes. The dataset can be downloaded at https://canvas.uw.edu/courses/1256537/files/54325781/download?download_frd=1 We will split the dataset into three subsets: train, validation, and test. We will perform cross-validation on the train and validation set to pick a good smoothing parameter alpha. Then, we will evaluate the model performance (classification accuracy) using the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Load Dataset\n",
    "\n",
    "First let's load the dataset and split it into train, validation, and test. The code is already written for you. Please feel free to `print` or explore the dataset on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv(\"rotten-tomatoes.csv\")\n",
    "    df = df[df.fresh != 'none']\n",
    "    y =  pd.get_dummies(df.fresh).fresh\n",
    "    # split train, validation, and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.quote, y, test_size=0.1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Naive Bayes\n",
    "\n",
    "1.1 Let's vectorize the quotes by counting word frequencies and fit a Naive Bayes classifier on the *training* set. Because our features are discrete word counts, we will use `MultinomialNB` from `sklearn` (https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html). Please run the code below and report the train and validation accuracy (Hint: 92.6%, 77.3%).\n",
    "\n",
    "1.2 The smoothing prior `alpha` accounts for features not present in the learning samples and prevents zero probabilities in further computations. Setting `alpha =1` is called *Laplace* smoothing; setting `alpha = 0.1` is called *Lidstone* smoothing, setting `alpha = 0` means no smoothing. Please set `alpha` to `0, 0.1, 1` in the code below and report the train and validation accuracy. Among the three parameter settings, which gives the best model performance (i.e., the highest validation accuracy)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9242800625632532\n",
      "validation accuracy 0.7913907284768212\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vectorizer = vectorizer.fit(X_train)\n",
    "\n",
    "clf = MultinomialNB(alpha = 1) # todo: set alpha = 0, 0.1, 1\n",
    "\n",
    "X_train_vec = vectorizer.transform(X_train).toarray()\n",
    "clf.fit(X_train_vec, y_train)\n",
    "print('train accuracy:', clf.score(X_train_vec, y_train))\n",
    "\n",
    "X_val_vec = vectorizer.transform(X_val).toarray()\n",
    "print('validation accuracy', clf.score(X_val_vec, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The train accuracy is 92.6% and validation is 75.8% (with alpha = 1). From the 3 parameters for alpha, alpha = 1 gives the highest validation accuracy of 0.758."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Cross-Validation to Pick Smoothing Parameter\n",
    "\n",
    "2.1 Now let's try 20 different `alpha` values. Please complete the code below and plot the train and validation accuracies against `alpha` values. Please plot two lines, put `alpha` on the x axis, train and validation accuracy on the y axis. Please use color blue for the train accuracy and orange for the validation accuracy.\n",
    "\n",
    "2.2 Based on your plot, which `alpha` value is the best for model performance (i.e., pick the `alpha` with the best *validation* accuracy)? Report the optimal `alpha` and its train and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy 0.9580458183825559\n",
      "validation accuracy 0.7649006622516556\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy 0.9547336461495998\n",
      "validation accuracy 0.7756622516556292\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.9526175361118778\n",
      "validation accuracy 0.777317880794702\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.9504094212899071\n",
      "validation accuracy 0.7839403973509934\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.9485693256049315\n",
      "validation accuracy 0.7831125827814569\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.947465268193946\n",
      "validation accuracy 0.7847682119205298\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.9456251725089705\n",
      "validation accuracy 0.7814569536423841\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.9431410433342534\n",
      "validation accuracy 0.7814569536423841\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.9414849572177754\n",
      "validation accuracy 0.7855960264900662\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.9404729045910387\n",
      "validation accuracy 0.7880794701986755\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.9387248136903119\n",
      "validation accuracy 0.7880794701986755\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.937436746710829\n",
      "validation accuracy 0.7889072847682119\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.934860612751863\n",
      "validation accuracy 0.7913907284768212\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.933204526635385\n",
      "validation accuracy 0.7905629139072847\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.9322844787928972\n",
      "validation accuracy 0.7913907284768212\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.9310884165976631\n",
      "validation accuracy 0.7897350993377483\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.9296163400496826\n",
      "validation accuracy 0.7897350993377483\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.927776244364707\n",
      "validation accuracy 0.7889072847682119\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.9265801821694728\n",
      "validation accuracy 0.7913907284768212\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.9255681295427363\n",
      "validation accuracy 0.7897350993377483\n",
      "alpha: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "train accuracy 0.9242800625632532\n",
      "validation accuracy 0.7913907284768212\n"
     ]
    }
   ],
   "source": [
    "alpha = np.arange(0,1.05,0.05)\n",
    "# todo: fit clf on train, report train and validation accuracy\n",
    "training = []\n",
    "validation = []\n",
    "for x in alpha:\n",
    "    print(\"alpha:\", alpha)\n",
    "    clf = MultinomialNB(alpha = x) \n",
    "\n",
    "    X_train_vec = vectorizer.transform(X_train).toarray()\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    train_score = clf.score(X_train_vec, y_train)\n",
    "    print('train accuracy', train_score)\n",
    "    training.append(train_score)\n",
    "\n",
    "    X_val_vec = vectorizer.transform(X_val).toarray()\n",
    "    val_score = clf.score(X_val_vec, y_val)\n",
    "    print('validation accuracy', val_score)\n",
    "    validation.append(val_score)\n",
    "\n",
    "    clf.fit(X_val_vec, y_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a104a9400>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# todo: plot x = alpha, y = accuracy, color = [train, validation]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(alpha, training, color = 'blue')\n",
    "plt.plot(alpha, validation, color = 'orange')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9210068725676906\n",
      "validation accuracy 0.9097682119205298\n"
     ]
    }
   ],
   "source": [
    "# combine train and validation to form a new train set\n",
    "X_train_total = X_train.append(X_val)\n",
    "y_train_total = y_train.append(y_val)\n",
    "\n",
    "# todo: fit Naive Bayes classifier on X_train_total and y_train_total\n",
    "clf = MultinomialNB(alpha = 1) # todo: set alpha = 0, 0.1, 1\n",
    "\n",
    "X_train_vec = vectorizer.transform(X_train_total).toarray()\n",
    "clf.fit(X_train_vec, y_train_total)\n",
    "print('train accuracy:', clf.score(X_train_vec, y_train_total))\n",
    "\n",
    "# todo: evaluate model performance on X_test and y_test, report test accuracy\n",
    "X_val_vec = vectorizer.transform(X_val).toarray()\n",
    "print('validation accuracy', clf.score(X_val_vec, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Evaluate on Test Set\n",
    "\n",
    "3.1 With the optimal `alpha` you found in step 2, fit the Naive Bayes classifer on (train + validation) set and evaluate the model performance on the test set. Report the test accuracy. \n",
    "\n",
    "Note: After measuring test accuracy, do **not** change `alpha` any more. You should only change `alpha` during cross-validation (step 2). If you change `alpha` after looking at test acccuracy, you leak information from the test set to the model and your test accuracy will not be an unbiased estimator of the model's prediction accuracy any more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9223317048935994\n",
      "validation accuracy 0.9105960264900662\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha = 0.95) \n",
    "\n",
    "X_train_vec = vectorizer.transform(X_train_total).toarray()\n",
    "clf.fit(X_train_vec, y_train_total)\n",
    "print('train accuracy:', clf.score(X_train_vec, y_train_total))\n",
    "\n",
    "# todo: evaluate model performance on X_test and y_test, report test accuracy\n",
    "X_val_vec = vectorizer.transform(X_val).toarray()\n",
    "print('validation accuracy', clf.score(X_val_vec, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
